{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hydra\n",
    "import torch\n",
    "from audiocraft.models import MultiBandDiffusion\n",
    "from audiotools import AudioSignal\n",
    "from huggingface_hub import hf_hub_download\n",
    "\n",
    "from pflow_encodec.data.tokenizer import EncodecTokenizer, TextTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(ckpt_path, device=\"cpu\"):\n",
    "    ckpt = torch.load(ckpt_path, map_location=\"cpu\")\n",
    "\n",
    "    model = hydra.utils.instantiate(ckpt[\"model_config\"])\n",
    "    model.load_state_dict(ckpt[\"state_dict\"])\n",
    "    model = model.eval().to(device)\n",
    "\n",
    "    return model, ckpt[\"data_config\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_path = hf_hub_download(repo_id=\"seastar105/pflow-encodec-ejk\", filename=\"multilingual_base_bs100x4.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, data_config = load_model(ckpt_path, \"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e_prompt = hf_hub_download(repo_id=\"seastar105/pflow-encodec-ejk\", filename=\"samples/libritts_r_prompt.wav\")\n",
    "j_prompt = hf_hub_download(repo_id=\"seastar105/pflow-encodec-ejk\", filename=\"samples/jsut_prompt.wav\")\n",
    "k_prompt = hf_hub_download(repo_id=\"seastar105/pflow-encodec-ejk\", filename=\"samples/kss_prompt.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_tokenizer = TextTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encodec_tokenizer = EncodecTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mbd_model = MultiBandDiffusion.get_mbd_24khz(bw=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.inference_mode()\n",
    "def pflow_inference(\n",
    "    model, text, prompt_path, data_config, cfg_scale=1.0, n_steps=16, ode_method=\"midpoint\", return_latent=False\n",
    "):\n",
    "    device = next(model.parameters()).device\n",
    "    prompt = encodec_tokenizer.encode_file(prompt_path).to(device)\n",
    "    mean = data_config[\"mean\"]\n",
    "    std = data_config[\"std\"]\n",
    "    upscale_ratio = data_config[\"text2latent_ratio\"]\n",
    "\n",
    "    text_token = text_tokenizer.encode_text(text).to(device).unsqueeze(0)\n",
    "    prompt = (prompt - mean) / std\n",
    "    result = model.generate(\n",
    "        text_token, prompt, cfg_scale=cfg_scale, n_steps=n_steps, ode_method=ode_method, upscale_ratio=upscale_ratio\n",
    "    )\n",
    "    result = result * std + mean\n",
    "    if return_latent:\n",
    "        return result.cpu()\n",
    "    recon = encodec_tokenizer.decode_latents(result.to(device=encodec_tokenizer.device, dtype=encodec_tokenizer.dtype))\n",
    "    return recon.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.inference_mode()\n",
    "def mbd_decode(mbd_model, latent):\n",
    "    codes = encodec_tokenizer.quantize_latents(latent.to(device=encodec_tokenizer.device))\n",
    "    recon = mbd_model.tokens_to_wav(codes[:, :8, :])\n",
    "    return recon.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e_text = \"P-Flow encodec is Text-to-Speech model trained on Encodec latent space, using Flow Matching.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latents = pflow_inference(\n",
    "    model, e_text, e_prompt, data_config, cfg_scale=1.2, n_steps=16, ode_method=\"midpoint\", return_latent=True\n",
    ")\n",
    "pflow_result = (\n",
    "    encodec_tokenizer.decode_latents(latents.to(device=encodec_tokenizer.device, dtype=encodec_tokenizer.dtype))\n",
    "    .detach()\n",
    "    .cpu()\n",
    ")\n",
    "pflow_signal = AudioSignal(pflow_result, 24000).normalize(-23).ensure_max_of_audio()\n",
    "pflow_signal.embed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mbd_recon = mbd_decode(mbd_model, latents)\n",
    "mbd_signal = AudioSignal(mbd_recon, 24000).normalize(-23).ensure_max_of_audio()\n",
    "mbd_signal.embed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "j_text = \"こんにちは、初めまして。あなたの名前はなんですか？これは音声合成モデルから作られた音声です。\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latents = pflow_inference(\n",
    "    model, j_text, j_prompt, data_config, cfg_scale=1.2, n_steps=16, ode_method=\"midpoint\", return_latent=True\n",
    ")\n",
    "pflow_result = (\n",
    "    encodec_tokenizer.decode_latents(latents.to(device=encodec_tokenizer.device, dtype=encodec_tokenizer.dtype))\n",
    "    .detach()\n",
    "    .cpu()\n",
    ")\n",
    "pflow_signal = AudioSignal(pflow_result, 24000).normalize(-23).ensure_max_of_audio()\n",
    "pflow_signal.embed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mbd_recon = mbd_decode(mbd_model, latents)\n",
    "mbd_signal = AudioSignal(mbd_recon, 24000).normalize(-23).ensure_max_of_audio()\n",
    "mbd_signal.embed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_text = \"백남준은 미디어 아트의 개척자로서 다양한 테크놀로지를 이용하여 실험적이고 창의적으로 작업했다.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latents = pflow_inference(\n",
    "    model, k_text, k_prompt, data_config, cfg_scale=1.2, n_steps=16, ode_method=\"midpoint\", return_latent=True\n",
    ")\n",
    "pflow_result = (\n",
    "    encodec_tokenizer.decode_latents(latents.to(device=encodec_tokenizer.device, dtype=encodec_tokenizer.dtype))\n",
    "    .detach()\n",
    "    .cpu()\n",
    ")\n",
    "pflow_signal = AudioSignal(pflow_result, 24000).normalize(-23).ensure_max_of_audio()\n",
    "pflow_signal.embed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mbd_recon = mbd_decode(mbd_model, latents)\n",
    "mbd_signal = AudioSignal(mbd_recon, 24000).normalize(-23).ensure_max_of_audio()\n",
    "mbd_signal.embed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "code_text = \"There's famous japanese sentence, つきがきれいですね, which means 나는 당신을 사랑합니다.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latents = pflow_inference(\n",
    "    model, code_text, e_prompt, data_config, cfg_scale=1.2, n_steps=16, ode_method=\"midpoint\", return_latent=True\n",
    ")\n",
    "pflow_result = (\n",
    "    encodec_tokenizer.decode_latents(latents.to(device=encodec_tokenizer.device, dtype=encodec_tokenizer.dtype))\n",
    "    .detach()\n",
    "    .cpu()\n",
    ")\n",
    "pflow_signal = AudioSignal(pflow_result, 24000).normalize(-23).ensure_max_of_audio()\n",
    "pflow_signal.embed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mbd_recon = mbd_decode(mbd_model, latents)\n",
    "mbd_signal = AudioSignal(mbd_recon, 24000).normalize(-23).ensure_max_of_audio()\n",
    "mbd_signal.embed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latents = pflow_inference(\n",
    "    model, code_text, j_prompt, data_config, cfg_scale=1.2, n_steps=16, ode_method=\"midpoint\", return_latent=True\n",
    ")\n",
    "pflow_result = (\n",
    "    encodec_tokenizer.decode_latents(latents.to(device=encodec_tokenizer.device, dtype=encodec_tokenizer.dtype))\n",
    "    .detach()\n",
    "    .cpu()\n",
    ")\n",
    "pflow_signal = AudioSignal(pflow_result, 24000).normalize(-23).ensure_max_of_audio()\n",
    "pflow_signal.embed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mbd_recon = mbd_decode(mbd_model, latents)\n",
    "mbd_signal = AudioSignal(mbd_recon, 24000).normalize(-23).ensure_max_of_audio()\n",
    "mbd_signal.embed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latents = pflow_inference(\n",
    "    model, code_text, k_prompt, data_config, cfg_scale=1.2, n_steps=16, ode_method=\"midpoint\", return_latent=True\n",
    ")\n",
    "pflow_result = (\n",
    "    encodec_tokenizer.decode_latents(latents.to(device=encodec_tokenizer.device, dtype=encodec_tokenizer.dtype))\n",
    "    .detach()\n",
    "    .cpu()\n",
    ")\n",
    "pflow_signal = AudioSignal(pflow_result, 24000).normalize(-23).ensure_max_of_audio()\n",
    "pflow_signal.embed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mbd_recon = mbd_decode(mbd_model, latents)\n",
    "mbd_signal = AudioSignal(mbd_recon, 24000).normalize(-23).ensure_max_of_audio()\n",
    "mbd_signal.embed()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pflow-encodec",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
